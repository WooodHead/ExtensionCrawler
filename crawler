#!/usr/bin/env python3
#
# Copyright (C) 2016,2017 The University of Sheffield, UK
# 
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#

import os
import sys
import glob
import re
import requests
from datetime import datetime, timezone
import ExtensionCrawler.discover
import ExtensionCrawler.archive


def write_text(dir,fname,text):
     with open(os.path.join(dir, fname), 'w') as f:
        f.write(text)

def store_request_metadata(dir,fname, request):
    write_text(dir, fname + ".headers", str(request.headers))
    write_text(dir, fname + ".status", str(request.status_code))
    write_text(dir, fname + ".url", str(request.url))

def store_request_text(dir,fname,request):
    write_text(dir,fname,request.text)
    store_request_metadata(dir,fname,request)
    
def log(verbose,msg):
    if verbose:
        sys.stdout.write(msg)
    
def update_overview(dir, verbose, ext_id):
    log(verbose,"           * overview page: ")
    res = requests.get(ExtensionCrawler.config.const_overview_url(ext_id))
    log(verbose, "{}\n".format(str(res.status_code)))
    store_request_text(dir, 'overview.html', res)
  
    return True


def update_crx(dir, verbose, ext_id):
    log(verbose,"           * crx archive:   ")

    res = requests.get(
        ExtensionCrawler.config.const_download_url().format(ext_id),
        stream=True)
    log(verbose,"{}\n".format(str(res.status_code)))

    extfilename = os.path.basename(res.url)
    store_request_metadata(dir, extfilename, res)

    with open(os.path.join(dir, extfilename), 'wb') as f:
        for chunk in res.iter_content(chunk_size=512 * 1024):
            if chunk:  # filter out keep-alive new chunks
                f.write(chunk)

    return True


def update_reviews(dir, verbose, ext_id):
    log(verbose, "           * review page:   ")
    res = requests.post(
        ExtensionCrawler.config.const_review_url(),
        data=ExtensionCrawler.config.const_review_payload(ext_id, "0", "100"))
    log(verbose, "{}/".format(str(res.status_code)))
    store_request_text(dir, 'reviews000-099.text', res)
    res = requests.post(
        ExtensionCrawler.config.const_review_url(),
        data=ExtensionCrawler.config.const_review_payload(ext_id, "0", "100"))
    log(verbose, "{}\n".format(str(res.status_code)))
    store_request_text(dir, 'reviews100-199.text', res)

    return True


def update_support(dir, verbose, ext_id):
    log(verbose, "           * support page:  ")
    res = requests.post(
        ExtensionCrawler.config.const_support_url(),
        data=ExtensionCrawler.config.const_support_payload(ext_id, "0", "100"))
    log(verbose, "{}/".format(str(res.status_code)))
    store_request_text(dir, 'support000-099.text', res)
    res = requests.post(
        ExtensionCrawler.config.const_support_url(),
        data=ExtensionCrawler.config.const_support_payload(ext_id, "100",
                                                           "100"))
    log(verbose, "{}\n".format(str(res.status_code)))
    store_request_text(dir, 'support100-199.text', res)

    return True


def update_extension(archivedir, verbose, forums, ext_id):
    log(verbose, "    Updating {}".format(ext_id))
    if forums:
        log(verbose, " (including forums)")
    log(verbose, "\n")
    date = datetime.now(timezone.utc).isoformat()
    dir = os.path.join(
        os.path.join(archivedir,
                     ExtensionCrawler.archive.get_local_archive_dir(ext_id)),
        date)
    os.makedirs(dir, exist_ok=True)
    update_overview(dir, verbose, ext_id)
    update_crx(dir, verbose, ext_id)
    if forums:
        update_reviews(dir, verbose, ext_id)
        update_support(dir, verbose, ext_id)


def update_extensions(archivedir, verbose, forums_ext_ids, known_ext_ids,
                      new_ext_ids):
    def update_forums(ext_id):
        return (ext_id in forums_ext_ids)

    ext_ids = known_ext_ids + new_ext_ids
    log(verbose,
            "Updating {} extensions ({} new, {} including forums)\n".format(
                len(ext_ids), len(new_ext_ids), len(forums_ext_ids)))
    return list(map(lambda ext_id: update_extension(archivedir, verbose,
                                                    update_forums(ext_id), ext_id),
                    ext_ids))


def get_existing_ids(archivedir, verbose):
    byte = '[0-9a-z][0-9a-z][0-9a-z][0-9a-z][0-9a-z][0-9a-z][0-9a-z][0-9a-z]'
    word = byte + byte + byte + byte
    return list(
        map(lambda d: re.sub("^.*\/", "", d),
            glob.glob(os.path.join(archivedir, "*", word))))


def get_forum_ext_ids(confdir, verbose):
    with open(os.path.join(confdir, "forums.conf")) as f:
        ids = f.readlines()
    ids = [x.strip() for x in ids]
    return ids


def get_new_ids(verbose, known_ids):
    log(verbose, "Discovering new ids ... \n")
    discovered_ids = ExtensionCrawler.discover.crawl_nearly_all_of_ext_ids()
    new_ids = list(set(discovered_ids) - set(known_ids))
    log(verbose, "  Discovered {} new extensions (out of {})\n".format(
            len(new_ids), len(discovered_ids)))
    return new_ids


def main():
    basedir = "."
    archive_dir = os.path.join(basedir, "archive")
    conf_dir = os.path.join(basedir, "conf")
    verbose = True
    skip_discovery = True

    log(verbose, "Configuration:\n")
    log(verbose, "  Base dir:       {}\n".format(basedir))
    log(verbose, "    Archive dir:  {}\n".format(archive_dir))
    log(verbose, "    Conf. dir:    {}\n".format(conf_dir))
    log(verbose, "  Skip discovery: {}\n".format(skip_discovery))

    forum_ext_ids = get_forum_ext_ids(conf_dir, verbose)
    existing_ids = get_existing_ids(archive_dir, verbose)
    known_ids = list(set(existing_ids) | set(forum_ext_ids))
    new_ids = []
    if not skip_discovery:
        new_ids = get_new_ids(verbose, known_ids)

    update_extensions(archive_dir, verbose, forum_ext_ids, existing_ids,
                      new_ids)


main()
